{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>meanfreq</th>\n","      <th>sd</th>\n","      <th>median</th>\n","      <th>Q25</th>\n","      <th>Q75</th>\n","      <th>IQR</th>\n","      <th>skew</th>\n","      <th>kurt</th>\n","      <th>sp.ent</th>\n","      <th>sfm</th>\n","      <th>...</th>\n","      <th>centroid</th>\n","      <th>meanfun</th>\n","      <th>minfun</th>\n","      <th>maxfun</th>\n","      <th>meandom</th>\n","      <th>mindom</th>\n","      <th>maxdom</th>\n","      <th>dfrange</th>\n","      <th>modindx</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.059781</td>\n","      <td>0.064241</td>\n","      <td>0.032027</td>\n","      <td>0.015071</td>\n","      <td>0.090193</td>\n","      <td>0.075122</td>\n","      <td>12.863462</td>\n","      <td>274.402906</td>\n","      <td>0.893369</td>\n","      <td>0.491918</td>\n","      <td>...</td>\n","      <td>0.059781</td>\n","      <td>0.084279</td>\n","      <td>0.015702</td>\n","      <td>0.275862</td>\n","      <td>0.007812</td>\n","      <td>0.007812</td>\n","      <td>0.007812</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>male</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.066009</td>\n","      <td>0.067310</td>\n","      <td>0.040229</td>\n","      <td>0.019414</td>\n","      <td>0.092666</td>\n","      <td>0.073252</td>\n","      <td>22.423285</td>\n","      <td>634.613855</td>\n","      <td>0.892193</td>\n","      <td>0.513724</td>\n","      <td>...</td>\n","      <td>0.066009</td>\n","      <td>0.107937</td>\n","      <td>0.015826</td>\n","      <td>0.250000</td>\n","      <td>0.009014</td>\n","      <td>0.007812</td>\n","      <td>0.054688</td>\n","      <td>0.046875</td>\n","      <td>0.052632</td>\n","      <td>male</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.077316</td>\n","      <td>0.083829</td>\n","      <td>0.036718</td>\n","      <td>0.008701</td>\n","      <td>0.131908</td>\n","      <td>0.123207</td>\n","      <td>30.757155</td>\n","      <td>1024.927705</td>\n","      <td>0.846389</td>\n","      <td>0.478905</td>\n","      <td>...</td>\n","      <td>0.077316</td>\n","      <td>0.098706</td>\n","      <td>0.015656</td>\n","      <td>0.271186</td>\n","      <td>0.007990</td>\n","      <td>0.007812</td>\n","      <td>0.015625</td>\n","      <td>0.007812</td>\n","      <td>0.046512</td>\n","      <td>male</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.151228</td>\n","      <td>0.072111</td>\n","      <td>0.158011</td>\n","      <td>0.096582</td>\n","      <td>0.207955</td>\n","      <td>0.111374</td>\n","      <td>1.232831</td>\n","      <td>4.177296</td>\n","      <td>0.963322</td>\n","      <td>0.727232</td>\n","      <td>...</td>\n","      <td>0.151228</td>\n","      <td>0.088965</td>\n","      <td>0.017798</td>\n","      <td>0.250000</td>\n","      <td>0.201497</td>\n","      <td>0.007812</td>\n","      <td>0.562500</td>\n","      <td>0.554688</td>\n","      <td>0.247119</td>\n","      <td>male</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.135120</td>\n","      <td>0.079146</td>\n","      <td>0.124656</td>\n","      <td>0.078720</td>\n","      <td>0.206045</td>\n","      <td>0.127325</td>\n","      <td>1.101174</td>\n","      <td>4.333713</td>\n","      <td>0.971955</td>\n","      <td>0.783568</td>\n","      <td>...</td>\n","      <td>0.135120</td>\n","      <td>0.106398</td>\n","      <td>0.016931</td>\n","      <td>0.266667</td>\n","      <td>0.712812</td>\n","      <td>0.007812</td>\n","      <td>5.484375</td>\n","      <td>5.476562</td>\n","      <td>0.208274</td>\n","      <td>male</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["   meanfreq        sd    median       Q25       Q75       IQR       skew   \n","0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462  \\\n","1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n","2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n","3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n","4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n","\n","          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun   \n","0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702  \\\n","1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n","2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n","3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n","4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n","\n","     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n","0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n","1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n","2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n","3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n","4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n","\n","[5 rows x 21 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["voice=pd.read_csv('voice.csv')\n","voice.head()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["array(['female', 'male'], dtype=object)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","voice[\"label\"] = le.fit_transform(voice[\"label\"])\n","le.classes_"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>meanfreq</th>\n","      <th>sd</th>\n","      <th>median</th>\n","      <th>Q25</th>\n","      <th>Q75</th>\n","      <th>IQR</th>\n","      <th>skew</th>\n","      <th>kurt</th>\n","      <th>sp.ent</th>\n","      <th>sfm</th>\n","      <th>...</th>\n","      <th>centroid</th>\n","      <th>meanfun</th>\n","      <th>minfun</th>\n","      <th>maxfun</th>\n","      <th>meandom</th>\n","      <th>mindom</th>\n","      <th>maxdom</th>\n","      <th>dfrange</th>\n","      <th>modindx</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3163</th>\n","      <td>0.131884</td>\n","      <td>0.084734</td>\n","      <td>0.153707</td>\n","      <td>0.049285</td>\n","      <td>0.201144</td>\n","      <td>0.151859</td>\n","      <td>1.762129</td>\n","      <td>6.630383</td>\n","      <td>0.962934</td>\n","      <td>0.763182</td>\n","      <td>...</td>\n","      <td>0.131884</td>\n","      <td>0.182790</td>\n","      <td>0.083770</td>\n","      <td>0.262295</td>\n","      <td>0.832899</td>\n","      <td>0.007812</td>\n","      <td>4.210938</td>\n","      <td>4.203125</td>\n","      <td>0.161929</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3164</th>\n","      <td>0.116221</td>\n","      <td>0.089221</td>\n","      <td>0.076758</td>\n","      <td>0.042718</td>\n","      <td>0.204911</td>\n","      <td>0.162193</td>\n","      <td>0.693730</td>\n","      <td>2.503954</td>\n","      <td>0.960716</td>\n","      <td>0.709570</td>\n","      <td>...</td>\n","      <td>0.116221</td>\n","      <td>0.188980</td>\n","      <td>0.034409</td>\n","      <td>0.275862</td>\n","      <td>0.909856</td>\n","      <td>0.039062</td>\n","      <td>3.679688</td>\n","      <td>3.640625</td>\n","      <td>0.277897</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3165</th>\n","      <td>0.142056</td>\n","      <td>0.095798</td>\n","      <td>0.183731</td>\n","      <td>0.033424</td>\n","      <td>0.224360</td>\n","      <td>0.190936</td>\n","      <td>1.876502</td>\n","      <td>6.604509</td>\n","      <td>0.946854</td>\n","      <td>0.654196</td>\n","      <td>...</td>\n","      <td>0.142056</td>\n","      <td>0.209918</td>\n","      <td>0.039506</td>\n","      <td>0.275862</td>\n","      <td>0.494271</td>\n","      <td>0.007812</td>\n","      <td>2.937500</td>\n","      <td>2.929688</td>\n","      <td>0.194759</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3166</th>\n","      <td>0.143659</td>\n","      <td>0.090628</td>\n","      <td>0.184976</td>\n","      <td>0.043508</td>\n","      <td>0.219943</td>\n","      <td>0.176435</td>\n","      <td>1.591065</td>\n","      <td>5.388298</td>\n","      <td>0.950436</td>\n","      <td>0.675470</td>\n","      <td>...</td>\n","      <td>0.143659</td>\n","      <td>0.172375</td>\n","      <td>0.034483</td>\n","      <td>0.250000</td>\n","      <td>0.791360</td>\n","      <td>0.007812</td>\n","      <td>3.593750</td>\n","      <td>3.585938</td>\n","      <td>0.311002</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3167</th>\n","      <td>0.165509</td>\n","      <td>0.092884</td>\n","      <td>0.183044</td>\n","      <td>0.070072</td>\n","      <td>0.250827</td>\n","      <td>0.180756</td>\n","      <td>1.705029</td>\n","      <td>5.769115</td>\n","      <td>0.938829</td>\n","      <td>0.601529</td>\n","      <td>...</td>\n","      <td>0.165509</td>\n","      <td>0.185607</td>\n","      <td>0.062257</td>\n","      <td>0.271186</td>\n","      <td>0.227022</td>\n","      <td>0.007812</td>\n","      <td>0.554688</td>\n","      <td>0.546875</td>\n","      <td>0.350000</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["      meanfreq        sd    median       Q25       Q75       IQR      skew   \n","3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859  1.762129  \\\n","3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193  0.693730   \n","3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936  1.876502   \n","3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435  1.591065   \n","3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756  1.705029   \n","\n","          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun   \n","3163  6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770  \\\n","3164  2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n","3165  6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n","3166  5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n","3167  5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n","\n","        maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n","3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929      0  \n","3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897      0  \n","3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759      0  \n","3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002      0  \n","3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000      0  \n","\n","[5 rows x 21 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["voice.tail()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>meanfreq</th>\n","      <th>sd</th>\n","      <th>median</th>\n","      <th>Q25</th>\n","      <th>Q75</th>\n","      <th>IQR</th>\n","      <th>skew</th>\n","      <th>kurt</th>\n","      <th>sp.ent</th>\n","      <th>sfm</th>\n","      <th>...</th>\n","      <th>centroid</th>\n","      <th>meanfun</th>\n","      <th>minfun</th>\n","      <th>maxfun</th>\n","      <th>meandom</th>\n","      <th>mindom</th>\n","      <th>maxdom</th>\n","      <th>dfrange</th>\n","      <th>modindx</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.096419</td>\n","      <td>0.473409</td>\n","      <td>0.084125</td>\n","      <td>0.060063</td>\n","      <td>0.204956</td>\n","      <td>0.254828</td>\n","      <td>0.367853</td>\n","      <td>0.208279</td>\n","      <td>0.635798</td>\n","      <td>0.564526</td>\n","      <td>...</td>\n","      <td>0.096419</td>\n","      <td>0.157706</td>\n","      <td>0.030501</td>\n","      <td>0.981526</td>\n","      <td>0.000000</td>\n","      <td>0.006452</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.125828</td>\n","      <td>0.505075</td>\n","      <td>0.116900</td>\n","      <td>0.077635</td>\n","      <td>0.215683</td>\n","      <td>0.246961</td>\n","      <td>0.644279</td>\n","      <td>0.483766</td>\n","      <td>0.630964</td>\n","      <td>0.591578</td>\n","      <td>...</td>\n","      <td>0.125828</td>\n","      <td>0.287642</td>\n","      <td>0.031140</td>\n","      <td>0.834600</td>\n","      <td>0.000407</td>\n","      <td>0.006452</td>\n","      <td>0.002144</td>\n","      <td>0.002146</td>\n","      <td>0.056449</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.179222</td>\n","      <td>0.675536</td>\n","      <td>0.102873</td>\n","      <td>0.034284</td>\n","      <td>0.385912</td>\n","      <td>0.457148</td>\n","      <td>0.885255</td>\n","      <td>0.782275</td>\n","      <td>0.442738</td>\n","      <td>0.548382</td>\n","      <td>...</td>\n","      <td>0.179222</td>\n","      <td>0.236945</td>\n","      <td>0.030264</td>\n","      <td>0.954963</td>\n","      <td>0.000060</td>\n","      <td>0.006452</td>\n","      <td>0.000357</td>\n","      <td>0.000358</td>\n","      <td>0.049885</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.528261</td>\n","      <td>0.554611</td>\n","      <td>0.587559</td>\n","      <td>0.389906</td>\n","      <td>0.715802</td>\n","      <td>0.407358</td>\n","      <td>0.031549</td>\n","      <td>0.001613</td>\n","      <td>0.923261</td>\n","      <td>0.856457</td>\n","      <td>...</td>\n","      <td>0.528261</td>\n","      <td>0.183442</td>\n","      <td>0.041287</td>\n","      <td>0.834600</td>\n","      <td>0.065659</td>\n","      <td>0.006452</td>\n","      <td>0.025375</td>\n","      <td>0.025393</td>\n","      <td>0.265043</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.452195</td>\n","      <td>0.627209</td>\n","      <td>0.454272</td>\n","      <td>0.317627</td>\n","      <td>0.707515</td>\n","      <td>0.474474</td>\n","      <td>0.027742</td>\n","      <td>0.001732</td>\n","      <td>0.958736</td>\n","      <td>0.926348</td>\n","      <td>...</td>\n","      <td>0.452195</td>\n","      <td>0.279190</td>\n","      <td>0.036829</td>\n","      <td>0.929285</td>\n","      <td>0.238994</td>\n","      <td>0.006452</td>\n","      <td>0.250536</td>\n","      <td>0.250715</td>\n","      <td>0.223380</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["   meanfreq        sd    median       Q25       Q75       IQR      skew   \n","0  0.096419  0.473409  0.084125  0.060063  0.204956  0.254828  0.367853  \\\n","1  0.125828  0.505075  0.116900  0.077635  0.215683  0.246961  0.644279   \n","2  0.179222  0.675536  0.102873  0.034284  0.385912  0.457148  0.885255   \n","3  0.528261  0.554611  0.587559  0.389906  0.715802  0.407358  0.031549   \n","4  0.452195  0.627209  0.454272  0.317627  0.707515  0.474474  0.027742   \n","\n","       kurt    sp.ent       sfm  ...  centroid   meanfun    minfun    maxfun   \n","0  0.208279  0.635798  0.564526  ...  0.096419  0.157706  0.030501  0.981526  \\\n","1  0.483766  0.630964  0.591578  ...  0.125828  0.287642  0.031140  0.834600   \n","2  0.782275  0.442738  0.548382  ...  0.179222  0.236945  0.030264  0.954963   \n","3  0.001613  0.923261  0.856457  ...  0.528261  0.183442  0.041287  0.834600   \n","4  0.001732  0.958736  0.926348  ...  0.452195  0.279190  0.036829  0.929285   \n","\n","    meandom    mindom    maxdom   dfrange   modindx  label  \n","0  0.000000  0.006452  0.000000  0.000000  0.000000      1  \n","1  0.000407  0.006452  0.002144  0.002146  0.056449      1  \n","2  0.000060  0.006452  0.000357  0.000358  0.049885      1  \n","3  0.065659  0.006452  0.025375  0.025393  0.265043      1  \n","4  0.238994  0.006452  0.250536  0.250715  0.223380      1  \n","\n","[5 rows x 21 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["voice[:]=preprocessing.MinMaxScaler().fit_transform(voice)\n","voice.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["train, test = train_test_split(voice, test_size=0.3)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["x_train = train.iloc[:, :-1]\n","y_train = train[\"label\"]\n","x_test = test.iloc[:, :-1]\n","y_test = test[\"label\"]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n"]},{"data":{"text/plain":["(2217, 20)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["x_train.shape\n","print(type(x_train))\n","x_train=np.array(x_train)\n","x_test=np.array(x_test)\n","y_train=np.array(y_train)\n","y_test=np.array(y_test)\n","x_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["20\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","70/70 [==============================] - 1s 5ms/step - loss: 0.4795 - accuracy: 0.8566 - val_loss: 0.2502 - val_accuracy: 0.9075\n","Epoch 2/50\n","70/70 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.9517 - val_loss: 0.1319 - val_accuracy: 0.9495\n","Epoch 3/50\n","70/70 [==============================] - 0s 3ms/step - loss: 0.1035 - accuracy: 0.9702 - val_loss: 0.1017 - val_accuracy: 0.9642\n","Epoch 4/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9720 - val_loss: 0.1031 - val_accuracy: 0.9642\n","Epoch 5/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9707 - val_loss: 0.1001 - val_accuracy: 0.9685\n","Epoch 6/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9761 - val_loss: 0.1140 - val_accuracy: 0.9685\n","Epoch 7/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9820 - val_loss: 0.0924 - val_accuracy: 0.9695\n","Epoch 8/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9765 - val_loss: 0.0952 - val_accuracy: 0.9706\n","Epoch 9/50\n","70/70 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9779 - val_loss: 0.1018 - val_accuracy: 0.9632\n","Epoch 10/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9824 - val_loss: 0.0905 - val_accuracy: 0.9727\n","Epoch 11/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9824 - val_loss: 0.0819 - val_accuracy: 0.9727\n","Epoch 12/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9752 - val_loss: 0.0896 - val_accuracy: 0.9706\n","Epoch 13/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9820 - val_loss: 0.0904 - val_accuracy: 0.9685\n","Epoch 14/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9838 - val_loss: 0.0825 - val_accuracy: 0.9716\n","Epoch 15/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9842 - val_loss: 0.0874 - val_accuracy: 0.9727\n","Epoch 16/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9811 - val_loss: 0.0937 - val_accuracy: 0.9695\n","Epoch 17/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9811 - val_loss: 0.1039 - val_accuracy: 0.9664\n","Epoch 18/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9811 - val_loss: 0.0934 - val_accuracy: 0.9674\n","Epoch 19/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9847 - val_loss: 0.0867 - val_accuracy: 0.9685\n","Epoch 20/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9815 - val_loss: 0.0884 - val_accuracy: 0.9674\n","Epoch 21/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9851 - val_loss: 0.0926 - val_accuracy: 0.9653\n","Epoch 22/50\n","70/70 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9851 - val_loss: 0.0963 - val_accuracy: 0.9685\n","Epoch 23/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9833 - val_loss: 0.1014 - val_accuracy: 0.9685\n","Epoch 24/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9820 - val_loss: 0.0830 - val_accuracy: 0.9674\n","Epoch 25/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9815 - val_loss: 0.0912 - val_accuracy: 0.9653\n","Epoch 26/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0542 - accuracy: 0.9851 - val_loss: 0.0925 - val_accuracy: 0.9674\n","Epoch 27/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9820 - val_loss: 0.0889 - val_accuracy: 0.9716\n","Epoch 28/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9856 - val_loss: 0.0860 - val_accuracy: 0.9706\n","Epoch 29/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9820 - val_loss: 0.0999 - val_accuracy: 0.9653\n","Epoch 30/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9860 - val_loss: 0.0746 - val_accuracy: 0.9716\n","Epoch 31/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9811 - val_loss: 0.1016 - val_accuracy: 0.9611\n","Epoch 32/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9860 - val_loss: 0.0791 - val_accuracy: 0.9716\n","Epoch 33/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9874 - val_loss: 0.0814 - val_accuracy: 0.9695\n","Epoch 34/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9847 - val_loss: 0.1011 - val_accuracy: 0.9685\n","Epoch 35/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9820 - val_loss: 0.0835 - val_accuracy: 0.9716\n","Epoch 36/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9838 - val_loss: 0.1048 - val_accuracy: 0.9621\n","Epoch 37/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9820 - val_loss: 0.0829 - val_accuracy: 0.9716\n","Epoch 38/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.0727 - val_accuracy: 0.9727\n","Epoch 39/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9856 - val_loss: 0.0856 - val_accuracy: 0.9664\n","Epoch 40/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9711 - val_loss: 0.0760 - val_accuracy: 0.9695\n","Epoch 41/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9856 - val_loss: 0.0801 - val_accuracy: 0.9695\n","Epoch 42/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9851 - val_loss: 0.0965 - val_accuracy: 0.9642\n","Epoch 43/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9838 - val_loss: 0.0835 - val_accuracy: 0.9695\n","Epoch 44/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9842 - val_loss: 0.0822 - val_accuracy: 0.9695\n","Epoch 45/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9865 - val_loss: 0.0892 - val_accuracy: 0.9695\n","Epoch 46/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.0744 - val_accuracy: 0.9727\n","Epoch 47/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.0859 - val_accuracy: 0.9727\n","Epoch 48/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9824 - val_loss: 0.1058 - val_accuracy: 0.9674\n","Epoch 49/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9820 - val_loss: 0.0883 - val_accuracy: 0.9706\n","Epoch 50/50\n","70/70 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9820 - val_loss: 0.0899 - val_accuracy: 0.9664\n","30/30 [==============================] - 0s 968us/step - loss: 0.0899 - accuracy: 0.9664\n","Test Loss: 0.08990456163883209, Test Accuracy: 0.9663512110710144\n","INFO:tensorflow:Assets written to: voice_gender_model.model\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: voice_gender_model.model\\assets\n"]}],"source":["import tensorflow as tf\n","import keras\n","print(x_train.shape[1])\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(x_train.shape[1],)))\n","model.add(tf.keras.layers.Dense(64, activation='relu'))\n","model.add(tf.keras.layers.Dense(32, activation='relu'))\n","model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test))\n","\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n","\n","model.save('voice_gender_model.model')\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 90ms/step\n"]},{"data":{"text/plain":["array([[0.0011657]], dtype=float32)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["input_data=np.array([0.436911,0.684871,0.570361,0.198513,0.686256,0.577704,0.046854,0.003489,0.921665,0.901057,0.000000,0.436911,0.698762,0.380813,0.904450,0.279703,0.006452,0.192280,0.192418,0.173674])\n","model.predict(input_data.reshape(1,-1))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":2}
